# ğŸ§  Conceitos em Linguagem Simples

> Para quando precisares de explicar a alguÃ©m (ou a ti prÃ³prio Ã s 3 da manhÃ£ antes da defesa)

---

## ğŸ¯ Per-36 Metric

**O que Ã©:**
Um "composite score" que resume a contribuiÃ§Ã£o de um jogador, normalizado para 36 minutos.

**FÃ³rmula:**
```
per36 = (pts + 0.7Ã—reb + 0.7Ã—ast + 1.2Ã—stl + 1.2Ã—blk - 0.7Ã—tov) / minutos Ã— 36
```

**PorquÃª normalizar?**
- Jogador A: 1000 min, 500 pts totais â†’ 18 pts/36
- Jogador B: 100 min, 50 pts totais â†’ 18 pts/36
- ConclusÃ£o: mesma **eficiÃªncia**, diferentes **volumes**

**Cuidado:**
- Per-36 com poucos minutos Ã© instÃ¡vel (daÃ­ o floor de 12 min)

---

## ğŸ² Bayesian Shrinkage (Rookie Prior)

**Problema:**
Rookies com poucos minutos â†’ estatÃ­sticas muito ruidosas.

**SoluÃ§Ã£o:**
Combinar o observado com um "prior" (baseline da liga).

**Analogia:**
Imagina que nunca provaste comida de um restaurante novo.
- OpÃ§Ã£o A: confiar 100% na Ãºnica review que tem (pode ser fake)
- OpÃ§Ã£o B: combinar essa review com a mÃ©dia de restaurantes na cidade
â†’ **OpÃ§Ã£o B Ã© Bayesian shrinkage!**

**No cÃ³digo:**
```python
prior = mÃ©dia_dos_rookies_todos
forÃ§a_prior = 900 minutos equivalentes

se rookie jogou 300 minutos:
    peso_observado = 300
    peso_prior = 900
    per36_final = (300Ã—observado + 900Ã—prior) / 1200
                = 25% observado + 75% prior
```

**Resultado:**
- Rookies com poucos minutos â†’ puxados para a mÃ©dia
- Rookies com muitos minutos â†’ usam mais o seu prÃ³prio desempenho

---

## â° Temporal Dependence (Decay)

**Problema:**
Queres prever o per36 do ano que vem. Usas mÃ©dia histÃ³rica, mas...
- O que o jogador fez hÃ¡ 5 anos Ã© menos relevante que o que fez no ano passado.

**SoluÃ§Ã£o:**
Dar **mais peso** a Ã©pocas recentes.

**Como:**
```
peso_Ã©poca = decay^(anos_atrÃ¡s) Ã— minutos_jogados
```

**Exemplo visual:**
```
Jogador em 2024:

                     PESO
2024 (t):   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 1.00
2023 (t-1): [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]      0.60
2022 (t-2): [â–ˆâ–ˆâ–ˆâ–ˆ]         0.36
2021 (t-3): [â–ˆâ–ˆ]           0.22

Decay = 0.6
```

**InterpretaÃ§Ã£o:**
- Decay alto (0.8) â†’ passado conta bastante
- Decay mÃ©dio (0.6) â†’ balanÃ§o razoÃ¡vel âœ…
- Decay baixo (0.3) â†’ sÃ³ o recente importa

---

## ğŸ“Š Walk-Forward Validation

**O que Ã©:**
MÃ©todo de validaÃ§Ã£o para sÃ©ries temporais.

**Como funciona:**
```
Anos disponÃ­veis: 2015, 2016, 2017, 2018, 2019, 2020

Fold 1:
  Treino: 2015-2017
  Teste:  2018
  
Fold 2:
  Treino: 2015-2018
  Teste:  2019
  
Fold 3:
  Treino: 2015-2019
  Teste:  2020

MÃ©trica final: mÃ©dia dos 3 folds
```

**PorquÃª nÃ£o usar K-Fold normal?**
- K-Fold mistura passado e futuro â†’ data leakage!
- Walk-forward respeita a ordem temporal âœ…

---

## ğŸ¯ RÂ² (R-squared)

**O que Ã©:**
MÃ©trica que diz "quanto da variaÃ§Ã£o nos dados o modelo consegue explicar".

**InterpretaÃ§Ã£o:**
- RÂ² = 0.00 â†’ modelo nÃ£o explica nada (inÃºtil)
- RÂ² = 0.50 â†’ modelo explica 50% da variaÃ§Ã£o (ok)
- RÂ² = 0.70 â†’ modelo explica 70% (bom)
- RÂ² = 0.90 â†’ modelo explica 90% (muito bom, pode ser overfit)
- RÂ² = 1.00 â†’ modelo explica tudo (perfeito, quase sempre suspeito)

**No teu caso:**
```
RÂ² = 0.49 (temporal dependence)
```
â†’ Consegues explicar ~49% da variaÃ§Ã£o no per36 do ano seguinte usando o histÃ³rico.
Isso Ã© **razoÃ¡vel** para desporto (hÃ¡ muito ruÃ­do: lesÃµes, mudanÃ§as de equipa, etc.).

---

## ğŸ“‰ RMSE (Root Mean Squared Error)

**O que Ã©:**
Erro mÃ©dio do modelo, na **mesma escala** que a variÃ¡vel que estÃ¡s a prever.

**FÃ³rmula:**
```
RMSE = sqrt(mÃ©dia dos erros ao quadrado)
```

**Exemplo:**
```
PrevisÃµes vs Real:
Jogador A: previsto=15, real=18 â†’ erro=3
Jogador B: previsto=20, real=18 â†’ erro=2
Jogador C: previsto=10, real=18 â†’ erro=8

RMSE = sqrt((3Â² + 2Â² + 8Â²) / 3) = sqrt((9+4+64)/3) â‰ˆ 5.1
```

**InterpretaÃ§Ã£o:**
"Em mÃ©dia, o modelo erra por ~5.1 pontos de per36."

**No teu caso:**
```
RMSE = 3.27 (rookie threshold = 400 min)
```
â†’ Em mÃ©dia, erras por ~3.3 pontos ao prever o per36 do ano seguinte.
Isso Ã© bom (considerando que per36 mÃ©dio ~ 12-15).

---

## ğŸ€ Survival Bias (removido, mas importante saber)

**O que Ã©:**
ViÃ©s causado por sÃ³ veres quem "sobreviveu" na liga.

**Problema:**
```
Ano 1: entram 100 rookies
  - 80 jogam mal, saem da liga
  - 20 jogam bem, continuam

Ano 5: sÃ³ tens dados dos 20 que ficaram
â†’ MÃ©dias do "ano 5" estÃ£o enviesadas para cima!
```

**SoluÃ§Ã£o (nÃ£o implementada):**
Inverse Probability Weighting (IPW):
- Descobres P(chegar ao ano 5) = 20%
- DÃ¡s peso = 1/0.2 = 5 a cada sobrevivente
- Assim "representas" os 80 que saÃ­ram

**Porque nÃ£o usaste:**
- IPW pode dar pesos absurdos (atÃ© 9Ã—)
- Alguns jogadores dominariam o modelo inteiro
- Complexidade vs benefÃ­cio â†’ deixÃ¡mos para trabalho futuro

---

## ğŸ”‘ Leakage (Data Leakage)

**O que Ã©:**
Usar informaÃ§Ã£o do futuro para prever o futuro (batota acidental).

**Exemplo de leakage:**
```python
# ERRADO âŒ
df['per36_avg_all_time'] = df.groupby('playerID')['per36'].transform('mean')
# isto usa dados do futuro!

# CERTO âœ…
df['per36_avg_past'] = df.groupby('playerID')['per36'].shift(1).expanding().mean()
# sÃ³ usa dados atÃ© t-1
```

**No teu cÃ³digo:**
- âœ… Usas `.shift(1)` para criar `per36_next`
- âœ… SÃ³ usas Ã©pocas passadas para prever futuro
- âœ… Walk-forward validation respeita ordem temporal

---

## ğŸ“Š Stratified Validation

**O que Ã©:**
Validar o modelo **separadamente** em sub-grupos dos dados.

**PorquÃª:**
Modelo pode funcionar bem "em mÃ©dia" mas mal em casos especÃ­ficos.

**Exemplo:**
```
ValidaÃ§Ã£o global:
  RÂ² = 0.69 âœ… (parece bom)

ValidaÃ§Ã£o estratificada por minutos:
  <150 min:    RÂ² = 0.29 âŒ (terrÃ­vel)
  150-600 min: RÂ² = 0.57 âš ï¸  (ok)
  >600 min:    RÂ² = 0.76 âœ… (Ã³timo)
```

â†’ Descobres que o modelo **nÃ£o funciona** para jogadores com poucos minutos!
â†’ Justifica o threshold de 400 minutos.

---

## ğŸ”§ Grid Search

**O que Ã©:**
Testar vÃ¡rios valores de um parÃ¢metro e escolher o melhor.

**Exemplo:**
```python
# Qual o melhor rookie_min_minutes?
candidatos = [150, 300, 400, 600]

for threshold in candidatos:
    df_filtered = df[df['minutes'] >= threshold]
    rmse = avaliar_modelo(df_filtered)
    print(f"{threshold}: RMSE={rmse}")

# Output:
# 150: RMSE=5.23
# 300: RMSE=3.50
# 400: RMSE=3.27  â† MELHOR âœ…
# 600: RMSE=3.35

# Escolher: 400
```

---

## ğŸ“ˆ Autocorrelation

**O que Ã©:**
CorrelaÃ§Ã£o de uma variÃ¡vel **consigo mesma** ao longo do tempo.

**Exemplo:**
```
per36 do ano t  vs  per36 do ano t+1
    15                  16
    20                  19
    10                  12
    ...
    
corr = 0.69 â†’ alta autocorrelaÃ§Ã£o
```

**InterpretaÃ§Ã£o:**
- Alta autocorrelaÃ§Ã£o (0.7+) â†’ desempenho Ã© bastante estÃ¡vel
- Baixa autocorrelaÃ§Ã£o (0.3-) â†’ desempenho Ã© muito volÃ¡til

**No teu caso:**
```
autocorr(per36_t, per36_t+1) â‰ˆ 0.69
```
â†’ Jogadores tendem a manter-se consistentes ano-a-ano
â†’ Justifica usar histÃ³rico para prever futuro

---

## ğŸ“ Resumo dos Resumos

| Conceito | Em 5 palavras |
|----------|---------------|
| **Per-36** | EficiÃªncia normalizada por minutos |
| **Bayesian shrinkage** | Puxar outliers para mÃ©dia |
| **Decay** | Passado pesa menos progressivamente |
| **Walk-forward** | Validar respeitando ordem temporal |
| **RÂ²** | Percentagem de variaÃ§Ã£o explicada |
| **RMSE** | Erro mÃ©dio em unidades originais |
| **Survival bias** | SÃ³ vÃªs quem sobrevive |
| **Leakage** | Usar futuro para prever |
| **Grid search** | Testar tudo, escolher melhor |

---

**Dica final:**
Se te perguntarem algo que nÃ£o sabes responder na defesa:

> "Essa Ã© uma extensÃ£o interessante que nÃ£o explorÃ¡mos, mas estÃ¡ documentada
> no ficheiro TECHNICAL_DECISIONS.md como trabalho futuro."

ğŸ˜ğŸ‘Œ

